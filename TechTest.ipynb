{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TechTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9qJL0VLcG2Oh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для своего эксперимента я выбрала статью Y-Vector: Multiscale Waveform Encoder for Speaker Embedding. В статье предложен новый  multi-scale waveform\n",
        "encoder,который включает в себя три ветви, состоящие из сверточных слоёв,squeeze-and-excitation блоков и TDNN нейросетью.\n",
        "Отличительной особенностью подхода, предложенного, в статье является то, что нейросеть построенная по представленной архитектуре позволяет извлекать фичи из необработанных данных, в то время как до этого они создавались вручную.\n",
        "Для эксперимента я взяла датасет LIBRISPEECH и постаралась воспроизвести архитектуру из статьи : Multi-scale Filtering Layer,tf-SE Downsampling Block,Multi-level Feature Map Aggregation.\n",
        "К сожалению в самом конце сталкнулась с ошибкой, котору пока что не могу разрешить, поэтому не удалось продолжить эксперимент.\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "tSIrGEMGG3xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import glob\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torchaudio.datasets\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "#from torch.utils.data import Dataset\n",
        "#from datasets import load_dataset, load_metric\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.optim import SGD\n",
        "#from transformers import get_sheduler\n",
        "from tqdm.auto import tqdm\n",
        "import logging\n",
        "import math\n",
        "import sys"
      ],
      "metadata": {
        "id": "PiUwTGU0MnGp"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torchaudio.datasets.LIBRISPEECH(\"./\", url=\"train-clean-100\", download=True)\n",
        "test_loader = torchaudio.datasets.LIBRISPEECH(\"./\", url=\"test-clean\", download=True)"
      ],
      "metadata": {
        "id": "SMuFICTYMhV4"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "A7BBy8F_ZdYO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fp32GroupNorm(nn.GroupNorm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = F.group_norm(\n",
        "            inputs.float(),\n",
        "            self.num_groups,\n",
        "            self.weight.float() if self.weight is not None else None,\n",
        "            self.bias.float() if self.bias is not None else None,\n",
        "            self.eps,\n",
        "        )\n",
        "        return output.type_as(inputs)\n",
        "\n",
        "class Fp32LayerNorm(nn.LayerNorm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = F.layer_norm(\n",
        "            inputs.float(),\n",
        "            self.normalized_shape,\n",
        "            self.weight.float() if self.weight is not None else None,\n",
        "            self.bias.float() if self.bias is not None else None,\n",
        "            self.eps,\n",
        "        )\n",
        "        return output.type_as(inputs)\n",
        "\n",
        "class TransposeLast(nn.Module):\n",
        "    def __init__(self, deconstruct_idx=None):\n",
        "        super().__init__()\n",
        "        self.deconstruct_idx = deconstruct_idx\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.deconstruct_idx is not None:\n",
        "            x = x[self.deconstruct_idx]\n",
        "        return x.transpose(-2, -1)\n",
        "\n",
        "def norm_block(is_layer_norm, dim, affine=True, is_instance_norm=False):\n",
        "    if is_layer_norm:\n",
        "        mod = nn.Sequential(\n",
        "            TransposeLast(),\n",
        "            Fp32LayerNorm(dim, elementwise_affine=affine),\n",
        "            TransposeLast(),\n",
        "        )\n",
        "    else:\n",
        "        if is_instance_norm:\n",
        "            mod = Fp32GroupNorm(dim, dim, affine=False) # instance norm\n",
        "        else:\n",
        "            mod = Fp32GroupNorm(1, dim, affine=affine)  # layer norm\n",
        "\n",
        "    return "
      ],
      "metadata": {
        "id": "4dN2mgNmWw_6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fp32GroupNorm(nn.GroupNorm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = F.group_norm(\n",
        "            inputs.float(),\n",
        "            self.num_groups,\n",
        "            self.weight.float() if self.weight is not None else None,\n",
        "            self.bias.float() if self.bias is not None else None,\n",
        "            self.eps,\n",
        "        )\n",
        "        return output.type_as(inputs)\n",
        "\n",
        "def norm_block(is_layer_norm, dim, affine=True, is_instance_norm=False):\n",
        "    if is_layer_norm:\n",
        "        mod = nn.Sequential(\n",
        "            TransposeLast(),\n",
        "            Fp32LayerNorm(dim, elementwise_affine=affine),\n",
        "            TransposeLast(),\n",
        "        )\n",
        "    else:\n",
        "        if is_instance_norm:\n",
        "            mod = Fp32GroupNorm(dim, dim, affine=False) # instance norm\n",
        "        else:\n",
        "            mod = Fp32GroupNorm(1, dim, affine=affine)  # layer norm\n",
        "\n",
        "    return mod"
      ],
      "metadata": {
        "id": "_qsG2Hv44r1I"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.fgate = nn.Sequential(nn.Linear(channels, channels), nn.Sigmoid())\n",
        "        self.tgate = nn.Sequential(nn.Linear(channels, 1), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        \n",
        "        fg = self.fgate(x.mean(dim=-1))\n",
        "        x = x * fg.unsqueeze(-1)\n",
        "        \n",
        "        tg = x.permute(0, 2, 1).contiguous().view(-1, x.shape[1])\n",
        "        tg = self.tgate(tg).view(x.shape[0], x.shape[2]).unsqueeze(1)\n",
        "        out = x * tg\n",
        "        return out"
      ],
      "metadata": {
        "id": "TvbPAbbRI0wR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TDNNLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, output_dim,\n",
        "                 context_size, dilation=1):\n",
        "        '''\n",
        "        TDNN as defined by https://www.danielpovey.com/files/2015_interspeech_multisplice.pdf\n",
        "        Affine transformation not applied globally to all frames but smaller windows with local context\n",
        "        batch_norm: True to include batch normalisation after the non linearity\n",
        "        \n",
        "        Context size and dilation determine the frames selected\n",
        "        (although context size is not really defined in the traditional sense)\n",
        "        For example:\n",
        "            context size 5 and dilation 1 is equivalent to [-2,-1,0,1,2]\n",
        "            context size 3 and dilation 2 is equivalent to [-2, 0, 2]\n",
        "            context size 1 and dilation 1 is equivalent to [0]\n",
        "        '''\n",
        "        super(TDNNLayer, self).__init__()\n",
        "        self.context_size = context_size\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dilation = dilation\n",
        "        self.kernel = nn.Linear(input_dim*context_size, output_dim)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        '''\n",
        "        input: size (batch, input_features, seq_len)\n",
        "        outpu: size (batch, new_seq_len, output_features)\n",
        "        '''\n",
        "        \n",
        "        # ----------Convolution = unfold + matmul + fold\n",
        "        x = inputs\n",
        "        _, d, _ = x.shape\n",
        "        assert (d == self.input_dim), 'Input dimension was wrong. Expected ({}), got ({})'.format(self.input_dim, d)\n",
        "        x = x.unsqueeze(1)\n",
        "        \n",
        "        # Unfold input into smaller temporal contexts\n",
        "        x = F.unfold(x, (self.input_dim, self.context_size), \n",
        "                     stride=(self.input_dim, 1), \n",
        "                     dilation=(1, self.dilation))\n",
        "\n",
        "        # N, output_dim*context_size, new_t = x.shape\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.kernel(x) # matmul\n",
        "        \n",
        "        # transpose to channel first\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        return x\n",
        "    "
      ],
      "metadata": {
        "id": "ZG76LxcOa94n"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        non_affine_group_norm=False\n",
        "        super(FeatureExtractionModel, self).__init__()\n",
        "        self.branch1 = nn.Sequential(nn.Conv1d(1,90,12,16),\n",
        "                                     norm_block(is_layer_norm=False, dim=90, affine=not non_affine_group_norm,\n",
        "                                     is_instance_norm=True), \n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Conv1d(90,160,5,3),\n",
        "                                     norm_block(is_layer_norm=False, dim=160, affine=not non_affine_group_norm,\n",
        "                                     is_instance_norm=True), \n",
        "                                     nn.ReLU()\n",
        "                                   )\n",
        "        self.branch2 = nn.Sequential(nn.Conv1d(1,90,18,9),\n",
        "                                     norm_block(is_layer_norm=False, dim=90, affine=not non_affine_group_norm,\n",
        "                                     is_instance_norm=True), \n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Conv1d(90,160,5,2),\n",
        "                                     norm_block(is_layer_norm=False, dim=160, affine=not non_affine_group_norm,\n",
        "                           is_instance_norm=True), \n",
        "                                     nn.ReLU()\n",
        "                                    )\n",
        "        self.branch3 = nn.Sequential(nn.Conv1d(1,90, 36, 18),\n",
        "                                     norm_block(is_layer_norm=False, dim=90, affine=not non_affine_group_norm,\n",
        "                           is_instance_norm=True), \n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Conv1d(90,192, 5, 1,padding=2),\n",
        "                                     norm_block(is_layer_norm=False, dim=160, affine=not non_affine_group_norm,\n",
        "                           is_instance_norm=True), \n",
        "                                     nn.ReLU()\n",
        "                                    )\n",
        "       \n",
        "        self.skip1 = nn.MaxPool1d(kernel_size=5, stride=8)\n",
        "        self.skip2 = nn.MaxPool1d(kernel_size=3, stride=4, padding=1)\n",
        "\n",
        "        def forward(self, x):\n",
        "          # wave encoder\n",
        "         enc = []\n",
        "         ft_shape = []\n",
        "         for conv in self.conv_front:\n",
        "            enc.append(conv(x))\n",
        "            ft_shape.append(conv(x).shape[-1])\n",
        "            \n",
        "            ft_max = np.min(np.array(ft_shape))\n",
        "            enc = torch.cat((enc[0][:, :, :ft_max], enc[1][:, :, :ft_max], enc[2][:, :, :ft_max]), dim=1)\n",
        "        \n",
        "            skip1_out = self.skip1(enc)\n",
        "            out1 = self.branch1(enc)\n",
        "            skip2_out = self.skip2(out1)\n",
        "            out2 = self.branch2(out1)\n",
        "            out3= self.branch3(out2)\n",
        "            t_max = np.min(np.array([skip1_out.shape[-1], skip2_out.shape[-1], out3.shape[-1]]))\n",
        "            out = torch.cat((skip1_out[:, :, :t_max], skip2_out[:, :, :t_max], out3[:, :, :t_max]), dim=1)\n",
        "            output = self.am4(out)\n",
        "        \n",
        "       \n",
        "            return output"
      ],
      "metadata": {
        "id": "WtaDsSUD64VF"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TDNNBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, bn_dim,\n",
        "                 skip, context_size, dilation=1, \n",
        "                 bottleneck=False):\n",
        "        '''\n",
        "        TDNNBlock\n",
        "        '''\n",
        "        super(TDNNBlock, self).__init__()\n",
        "\n",
        "        # bn conv\n",
        "        self.bottleneck = bottleneck\n",
        "        if bottleneck:\n",
        "            self.bnconv1d = nn.Conv1d(input_dim, bn_dim, 1)\n",
        "            self.nonlinear1 = nn.PReLU()\n",
        "            self.norm1 = nn.GroupNorm(1, bn_dim, eps=1e-08)\n",
        "            self.tdnnblock = TDNNLayer(bn_dim, input_dim, context_size, dilation)\n",
        "        else:\n",
        "            self.tdnnblock = TDNNLayer(input_dim, input_dim, context_size, dilation)\n",
        "        \n",
        "        # tdnn\n",
        "        self.nonlinear2 = nn.PReLU()\n",
        "        self.norm2 = nn.GroupNorm(1, input_dim, eps=1e-08)\n",
        "        \n",
        "        # skip connection\n",
        "        self.skip = skip\n",
        "        if self.skip:\n",
        "            self.skip_out = nn.MaxPool1d(kernel_size=context_size, \n",
        "                                         stride=1, dilation=dilation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        input: size (batch, seq_len, input_features)\n",
        "        outpu: size (batch, new_seq_len, output_features)\n",
        "        '''\n",
        "        out = x\n",
        "        if self.bottleneck:\n",
        "            out = self.nonlinear1(self.bnconv1d(out))\n",
        "            out = self.norm1(out)\n",
        "        \n",
        "        out = self.nonlinear2(self.tdnnblock(out))\n",
        "        out = self.norm2(out)\n",
        "\n",
        "        if self.skip:\n",
        "            skip = self.skip_out(x)\n",
        "            return out, skip\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "class TDNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, filter_dim, input_dim, bn_dim,\n",
        "                 skip, context_size=3, layer=9, stack=1, \n",
        "                 bottleneck=False):\n",
        "        '''\n",
        "        stacked TDNN Blocks\n",
        "        '''\n",
        "        super(TDNN, self).__init__()\n",
        "        \n",
        "#         # BottleNeck Layer\n",
        "#         self.LN = nn.GroupNorm(1, filter_dim, eps=1e-8)\n",
        "#         self.BN_conv = nn.Conv1d(filter_dim, input_dim, 1)\n",
        "        \n",
        "        # Residual Connection\n",
        "        self.skip = skip\n",
        "        \n",
        "        # TDNN for feature extraction\n",
        "        self.receptive_field = 0\n",
        "        \n",
        "        self.tdnn = nn.ModuleList([])\n",
        "        for s in range(stack):\n",
        "            for i in range(layer):\n",
        "                self.tdnn.append(TDNNBlock(input_dim, bn_dim, self.skip, \n",
        "                                           context_size=3, dilation=2**i, \n",
        "                                           bottleneck=bottleneck))\n",
        "                \n",
        "            if i == 0 and s == 0:\n",
        "                self.receptive_field += context_size\n",
        "            else:\n",
        "                self.receptive_field += (context_size - 1) * 2 ** i\n",
        "                \n",
        "        print(\"Receptive field: {:3d} frames.\".format(self.receptive_field))\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        input: size (batch, seq_len, input_features)\n",
        "        outpu: size (batch, new_seq_len, output_features)\n",
        "        '''\n",
        "        \n",
        "#         output = self.BN_conv(self.LN(x))\n",
        "        \n",
        "        for i in range(len(self.tdnn)):\n",
        "            if self.skip:\n",
        "                output, skips = self.tdnn[i](x)\n",
        "                output = skips + output\n",
        "            else:\n",
        "                output = self.tdnn[i](output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "jO-H1sjPcsUP"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TDNN_Block(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=512, context_size=5, dilation=1, norm='bn', affine=True):\n",
        "        super(TDNN_Block, self).__init__()\n",
        "        if norm == 'bn':\n",
        "            norm_layer = nn.BatchNorm1d(output_dim, affine=affine)\n",
        "        elif norm == 'ln':\n",
        "#             norm_layer = nn.GroupNorm(1, output_dim, affine=affine)\n",
        "            norm_layer = Fp32GroupNorm(1, output_dim, affine=affine)\n",
        "        elif norm == 'in':\n",
        "            norm_layer = nn.GroupNorm(output_dim, output_dim, affine=False)\n",
        "        else:\n",
        "            raise ValueError('Norm should be {bn, ln, in}.')\n",
        "        self.tdnn_layer = nn.Sequential(\n",
        "            TDNNLayer(input_dim, output_dim, context_size, dilation),\n",
        "            norm_layer,\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.tdnn_layer(x)"
      ],
      "metadata": {
        "id": "SlRly9y8lMnc"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Downsampling(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Downsampling, self).__init__()\n",
        "      self.DS1= nn.Sequential(nn.Conv1d(512, 5, 2),\n",
        "                              nn.ReLU()\n",
        "                              )\n",
        "                               \n",
        "                               \n",
        "      self.DS1= nn.Sequential(nn.Conv1d(512, 3, 2),\n",
        "                              nn.ReLU())\n",
        "      self.DS1= nn.Sequential(nn.Conv1d(512, 3, 2),\n",
        "                                  nn.ReLU())\n",
        "      self.am2 = SEBlock(512)\n",
        "      self.am3 = SEBlock(512)\n",
        "      self.am4 = SEBlock(512*3)\n",
        "        \n",
        "      \n",
        "  def forward(self, x):\n",
        "      se=self.am2(x)\n",
        "      x=self.am2(se)\n",
        "      se=self.am2(se)\n",
        "      x=self.DS1(se)\n",
        "      out1 = self.am1(x)\n",
        "      return out1\n",
        "      "
      ],
      "metadata": {
        "id": "cDU7msHN8CbZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FrameAgregation(nn.Module):\n",
        "  def __init__(self, feature_dim=512, embed_dim=512, norm='bn', p_dropout=0.0):\n",
        "        super(FrameAgregation, self).__init__()\n",
        "        self.tdnn = nn.Sequential(\n",
        "            TDNN_Block(feature_dim, 512, 5, 1, norm=norm),\n",
        "            TDNN_Block(512, 512, 3, 2, norm=norm),\n",
        "            TDNN_Block(512, 512, 3, 3, norm=norm),\n",
        "            TDNN_Block(512, 512, 1, 1, norm=norm),\n",
        "            TDNN_Block(512, 1500, 1, 1, norm=norm),\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(3000, 512)\n",
        "        self.bn = nn.LayerNorm(512)\n",
        "        self.dropout_fc1 = nn.Dropout(p=p_dropout)\n",
        "        self.lrelu = nn.LeakyReLU(0.2)\n",
        "        self.fc2 = nn.Linear(512, embed_dim)\n",
        "    \n",
        "def forward(self, x):\n",
        "        # Note: x must be (batch_size, feat_dim, chunk_len)\n",
        "        x = self.tdnn(x)\n",
        "        \n",
        "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
        "        \n",
        "        x = self.dropout_fc1(self.lrelu(self.bn(self.fc1(stats))))\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n"
      ],
      "metadata": {
        "id": "1cfogvSWrfUp"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class architecture(nn.Module):\n",
        "    def __init__(self, embed_dim=512):\n",
        "        super(architecture, self).__init__()\n",
        "        \n",
        "        self.feature_encoder = FeatureExtractionModel()\n",
        "        self.downsampler=Downsampling()\n",
        "        self.aggregator = FrameAgregation(feature_dim=512*3, embed_dim=128, norm='ln')\n",
        "    def forward(self, x):\n",
        "        out = self.feature_encoder(x)\n",
        "        out= self.downsampler(out)\n",
        "        out = self.aggregator(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "tYOW8AKBqg8l"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model=architecture()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(my_model.parameters(), lr=0.01, momentum=0.9)\n",
        "epochs=20\n",
        "batch_num =64\n",
        "\n"
      ],
      "metadata": {
        "id": "EvF13pHSkGiV"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IterMeter(object):\n",
        "    \"\"\"keeps track of total iterations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "    with experiment.train():\n",
        "        for batch_idx, _data in enumerate(train_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            loss.backward()\n",
        "\n",
        "            experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
        "            experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
        "\n",
        "            optimizer.step()\n",
        "            iter_meter.step()\n",
        "            if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(spectrograms), data_len,\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter, experiment):\n",
        "    print('\\nevaluating…')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with experiment.test():\n",
        "        with torch.no_grad():\n",
        "            for I, _data in enumerate(test_loader):\n",
        "                spectrograms, labels, input_lengths, label_lengths = _data \n",
        "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "                output = model(spectrograms)  # (batch, time, n_class)\n",
        "                output = F.log_softmax(output, dim=2)\n",
        "                output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "                loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "                test_loss += loss.item() / len(test_loader)\n",
        "                                \n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "    \n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n"
      ],
      "metadata": {
        "id": "Mdt-qulOo-fy"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(model,train_dataset,test_dataset,learning_rate= 0.01, batch_size=batch_num , epochs=epochs):\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "      #torch.manual_seed(7) \n",
        "  model().to(device)\n",
        "  print(model)\n",
        "  print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "  iter_meter = IterMeter()\n",
        "  for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, epoch, iter_meter)\n",
        "        test(model, device, test_loader, criterion, epoch, iter_meter )\n"
      ],
      "metadata": {
        "id": "bNTKIi1Zpdpd"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experement=main(my_model,train_loader,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "jdWCKiXMuFCA",
        "outputId": "293a4a33-1a31-4db1-ab46-6bfb79c0af14"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-076bf6853b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-141-67fb6564a333>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, train_dataset, test_dataset, learning_rate, batch_size, epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0;31m#torch.manual_seed(7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Num Model Parameters'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
          ]
        }
      ]
    }
  ]
}